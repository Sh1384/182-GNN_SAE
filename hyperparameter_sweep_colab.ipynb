{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Hyperparameter Sweep with Optuna\n",
    "\n",
    "This notebook performs systematic hyperparameter optimization for the GCN model using Optuna on Google Colab.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Mount Google Drive** (to access your project files)\n",
    "2. **Install Dependencies** (Optuna if not already installed)\n",
    "3. **Run the Sweep** (50 trials by default, ~3-5 hours)\n",
    "4. **View Results** (visualizations and metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive and Set Up Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2201793421.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Set working directory to your project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "#from google.colab import files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set working directory to your project\n",
    "project_dir = '/content/drive/My Drive/182-GNN_SAE'  # Adjust path if needed\n",
    "os.chdir(project_dir)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"\\nDirectory contents:\")\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install optuna -q\n",
    "!pip install torch-geometric -q\n",
    "\n",
    "print(\"✓ Dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Import Libraries and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Import Functions from gnn_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from gnn_train.py\n",
    "from gnn_train import (\n",
    "    GraphDataset,\n",
    "    GCNModel,\n",
    "    GNNTrainer,\n",
    "    collate_fn,\n",
    "    load_all_graphs,\n",
    "    split_data\n",
    ")\n",
    "\n",
    "print(\"✓ Successfully imported all functions from gnn_train.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: Trial, train_loader: DataLoader, val_loader: DataLoader,\n",
    "              test_loader: DataLoader, device: str, num_epochs: int = 100) -> float:\n",
    "    \"\"\"\n",
    "    Optuna objective function to minimize validation loss.\n",
    "\n",
    "    Args:\n",
    "        trial: Optuna trial object\n",
    "        train_loader: Training DataLoader\n",
    "        val_loader: Validation DataLoader\n",
    "        test_loader: Test DataLoader\n",
    "        device: Device to train on\n",
    "        num_epochs: Maximum number of epochs\n",
    "\n",
    "    Returns:\n",
    "        Best validation loss achieved\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 16, 256, step=8)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5, step=0.05)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.0, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    mask_prob = trial.suggest_float('mask_prob', 0.1, 0.5, step=0.05)\n",
    "    early_stopping_patience = trial.suggest_int('early_stopping_patience', 5, 30, step=5)\n",
    "\n",
    "    # Create new model with suggested hyperparameters\n",
    "    model = GCNModel(input_dim=2, hidden_dim=hidden_dim, output_dim=1, dropout=dropout)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create new trainer with suggested learning rate and weight decay\n",
    "    trainer = GNNTrainer(model, device=device, learning_rate=learning_rate,\n",
    "                         weight_decay=weight_decay)\n",
    "\n",
    "    # Recreate dataloaders with new batch size\n",
    "    train_loader_new = DataLoader(\n",
    "        train_loader.dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    val_loader_new = DataLoader(\n",
    "        val_loader.dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = trainer.train_epoch(train_loader_new)\n",
    "        val_loss = trainer.validate(val_loader_new)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                break\n",
    "\n",
    "        # Report intermediate value for pruning\n",
    "        trial.report(val_loss, epoch)\n",
    "\n",
    "        # Prune unpromising trials\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "print(\"✓ Objective function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_history(trials_df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"Plot optimization history (loss over trials).\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    trials_df_sorted = trials_df.sort_values('value').reset_index(drop=True)\n",
    "    trials_df['best_value'] = trials_df['value'].cummin()\n",
    "\n",
    "    ax.plot(range(len(trials_df)), trials_df['value'], 'o-', alpha=0.6, label='Trial Loss')\n",
    "    ax.plot(range(len(trials_df)), trials_df['best_value'], 'r-', linewidth=2, label='Best Loss')\n",
    "\n",
    "    ax.set_xlabel('Trial Number', fontsize=12)\n",
    "    ax.set_ylabel('Validation Loss', fontsize=12)\n",
    "    ax.set_title('Optimization History', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = output_dir / 'optimization_history.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  Saved: {output_path.name}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_parameter_distributions(trials_df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"Plot distributions of hyperparameters colored by trial value.\"\"\"\n",
    "    param_cols = [col for col in trials_df.columns if col.startswith('params_')]\n",
    "    param_names = [col.replace('params_', '') for col in param_cols]\n",
    "\n",
    "    n_params = len(param_cols)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_params + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, (param_col, param_name) in enumerate(zip(param_cols, param_names)):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        unique_vals = trials_df[param_col].nunique()\n",
    "        is_categorical = unique_vals <= 10\n",
    "\n",
    "        if is_categorical:\n",
    "            data = trials_df.groupby(param_col)['value'].agg(['mean', 'std', 'count'])\n",
    "            x_labels = [str(x) for x in data.index]\n",
    "            y_vals = data['mean'].values\n",
    "            y_errs = data['std'].values\n",
    "\n",
    "            ax.bar(range(len(x_labels)), y_vals, yerr=y_errs, capsize=5, alpha=0.7)\n",
    "            ax.set_xticks(range(len(x_labels)))\n",
    "            ax.set_xticklabels(x_labels, rotation=45)\n",
    "            ax.set_ylabel('Mean Validation Loss', fontsize=10)\n",
    "            ax.set_title(f'{param_name}', fontsize=11, fontweight='bold')\n",
    "\n",
    "        else:\n",
    "            scatter = ax.scatter(\n",
    "                trials_df[param_col],\n",
    "                trials_df['value'],\n",
    "                c=trials_df['value'],\n",
    "                cmap='viridis',\n",
    "                alpha=0.6,\n",
    "                s=50\n",
    "            )\n",
    "            ax.set_xlabel(param_name, fontsize=10)\n",
    "            ax.set_ylabel('Validation Loss', fontsize=10)\n",
    "            ax.set_title(f'{param_name}', fontsize=11, fontweight='bold')\n",
    "            plt.colorbar(scatter, ax=ax, label='Loss')\n",
    "\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    for idx in range(n_params, len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = output_dir / 'parameter_distributions.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  Saved: {output_path.name}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_parameter_correlations(trials_df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"Plot correlation between parameters and validation loss.\"\"\"\n",
    "    param_cols = [col for col in trials_df.columns if col.startswith('params_')]\n",
    "    param_names = [col.replace('params_', '') for col in param_cols]\n",
    "\n",
    "    corr_data = []\n",
    "    for param_col, param_name in zip(param_cols, param_names):\n",
    "        unique_vals = trials_df[param_col].nunique()\n",
    "        if unique_vals > 10:\n",
    "            corr = trials_df[param_col].corr(trials_df['value'])\n",
    "            corr_data.append({'Parameter': param_name, 'Correlation': corr})\n",
    "\n",
    "    if not corr_data:\n",
    "        return\n",
    "\n",
    "    corr_df = pd.DataFrame(corr_data).sort_values('Correlation')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = ['red' if x < 0 else 'green' for x in corr_df['Correlation']]\n",
    "    ax.barh(corr_df['Parameter'], corr_df['Correlation'], color=colors, alpha=0.7)\n",
    "    ax.set_xlabel('Correlation with Validation Loss', fontsize=12)\n",
    "    ax.set_title('Parameter Importance (Correlation)', fontsize=14, fontweight='bold')\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = output_dir / 'parameter_correlations.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  Saved: {output_path.name}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_hyperparameter_heatmap(trials_df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"Plot heatmap of hyperparameters for top trials.\"\"\"\n",
    "    top_n = 10\n",
    "    param_cols = [col for col in trials_df.columns if col.startswith('params_')]\n",
    "\n",
    "    if not param_cols:\n",
    "        return\n",
    "\n",
    "    param_names = [col.replace('params_', '') for col in param_cols]\n",
    "\n",
    "    top_trials = trials_df.nsmallest(top_n, 'value')[param_cols].copy()\n",
    "    top_trials.columns = param_names\n",
    "\n",
    "    for col in top_trials.columns:\n",
    "        min_val = trials_df[f'params_{col}'].min()\n",
    "        max_val = trials_df[f'params_{col}'].max()\n",
    "        if max_val > min_val:\n",
    "            top_trials[col] = (top_trials[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.heatmap(\n",
    "        top_trials.T,\n",
    "        annot=False,\n",
    "        cmap='RdYlGn',\n",
    "        cbar_kws={'label': 'Normalized Value'},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f'Top {top_n} Trials Hyperparameters (Normalized)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Trial Rank (Best → Worst)', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = output_dir / 'top_trials_heatmap.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  Saved: {output_path.name}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_parameter_interactions(trials_df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"Plot interactions between key hyperparameters.\"\"\"\n",
    "    pairs = [\n",
    "        ('params_hidden_dim', 'params_dropout'),\n",
    "        ('params_learning_rate', 'params_weight_decay'),\n",
    "        ('params_hidden_dim', 'params_learning_rate'),\n",
    "        ('params_dropout', 'params_mask_prob'),\n",
    "    ]\n",
    "\n",
    "    valid_pairs = [(p1, p2) for p1, p2 in pairs if p1 in trials_df.columns and p2 in trials_df.columns]\n",
    "\n",
    "    if not valid_pairs:\n",
    "        return\n",
    "\n",
    "    n_pairs = len(valid_pairs)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_pairs + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, (param1, param2) in enumerate(valid_pairs):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        scatter = ax.scatter(\n",
    "            trials_df[param1],\n",
    "            trials_df[param2],\n",
    "            c=trials_df['value'],\n",
    "            cmap='viridis',\n",
    "            s=100,\n",
    "            alpha=0.6,\n",
    "            edgecolors='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "\n",
    "        param1_name = param1.replace('params_', '')\n",
    "        param2_name = param2.replace('params_', '')\n",
    "\n",
    "        ax.set_xlabel(param1_name, fontsize=11)\n",
    "        ax.set_ylabel(param2_name, fontsize=11)\n",
    "        ax.set_title(f'{param1_name} vs {param2_name}', fontsize=12, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Val Loss', fontsize=10)\n",
    "\n",
    "    for idx in range(len(valid_pairs), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = output_dir / 'parameter_interactions.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  Saved: {output_path.name}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_loss_distribution(trials_df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"Plot distribution of validation losses.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    axes[0].hist(trials_df['value'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[0].axvline(trials_df['value'].min(), color='red', linestyle='--', linewidth=2,\n",
    "                    label=f'Best: {trials_df[\"value\"].min():.4f}')\n",
    "    axes[0].axvline(trials_df['value'].mean(), color='green', linestyle='--', linewidth=2,\n",
    "                    label=f'Mean: {trials_df[\"value\"].mean():.4f}')\n",
    "    axes[0].set_xlabel('Validation Loss', fontsize=12)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0].set_title('Loss Distribution', fontsize=13, fontweight='bold')\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    box_data = trials_df['value'].values\n",
    "    bp = axes[1].boxplot(box_data, vert=True, patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    axes[1].set_ylabel('Validation Loss', fontsize=12)\n",
    "    axes[1].set_title('Loss Box Plot', fontsize=13, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[1].set_xticklabels(['All Trials'])\n",
    "\n",
    "    stats_text = f\"\"\"Min: {trials_df['value'].min():.6f}\n",
    "Max: {trials_df['value'].max():.6f}\n",
    "Mean: {trials_df['value'].mean():.6f}\n",
    "Std: {trials_df['value'].std():.6f}\"\"\"\n",
    "    axes[1].text(1.3, trials_df['value'].mean(), stats_text, fontsize=10,\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = output_dir / 'loss_distribution.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  Saved: {output_path.name}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_visualizations(trials_df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"Generate all visualizations from trials.\"\"\"\n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    plot_optimization_history(trials_df, output_dir)\n",
    "    plot_parameter_distributions(trials_df, output_dir)\n",
    "    plot_parameter_correlations(trials_df, output_dir)\n",
    "    plot_hyperparameter_heatmap(trials_df, output_dir)\n",
    "    plot_parameter_interactions(trials_df, output_dir)\n",
    "    plot_loss_distribution(trials_df, output_dir)\n",
    "    print(\"Visualization generation complete!\")\n",
    "\n",
    "print(\"✓ All visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_dir': 'virtual_graphs/data',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_trials': 50,  # Increase for more thorough search\n",
    "    'num_epochs': 100,  # Max epochs per trial\n",
    "    'output_dir': 'outputs/hyperparameter_sweep',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Load Data and Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "# Create output directory\n",
    "Path(CONFIG['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loading graphs...\")\n",
    "graph_paths = load_all_graphs(CONFIG['data_dir'], single_motif_only=True)\n",
    "print(f\"Loaded {len(graph_paths)} graphs\")\n",
    "\n",
    "print(\"\\nSplitting data...\")\n",
    "train_paths, val_paths, test_paths = split_data(\n",
    "    graph_paths,\n",
    "    train_ratio=0.8,\n",
    "    val_ratio=0.1,\n",
    "    stratify_by_motif=True\n",
    ")\n",
    "print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}, Test: {len(test_paths)}\")\n",
    "\n",
    "print(\"\\nCreating datasets...\")\n",
    "train_dataset = GraphDataset(train_paths, mask_prob=0.3, seed=CONFIG['seed'])\n",
    "val_dataset = GraphDataset(val_paths, mask_prob=0.3, seed=CONFIG['seed'])\n",
    "test_dataset = GraphDataset(test_paths, mask_prob=0.3, seed=CONFIG['seed'])\n",
    "\n",
    "print(\"\\nCreating dataloaders...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(\"✓ Data loading complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Run Hyperparameter Sweep\n",
    "\n",
    "**⏱️ This may take 3-5 hours for 50 trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"GCN HYPERPARAMETER SWEEP WITH OPTUNA\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Running {CONFIG['num_trials']} trials with up to {CONFIG['num_epochs']} epochs each\\n\")\n",
    "\n",
    "# Create Optuna study\n",
    "sampler = TPESampler(seed=CONFIG['seed'])\n",
    "pruner = MedianPruner(n_startup_trials=10, n_warmup_steps=0)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    "    study_name='gcn_optimization'\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(\n",
    "    lambda trial: objective(\n",
    "        trial, train_loader, val_loader, test_loader, CONFIG['device'], CONFIG['num_epochs']\n",
    "    ),\n",
    "    n_trials=CONFIG['num_trials'],\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"\\nBest Trial: {best_trial.number}\")\n",
    "print(f\"Best Validation Loss: {best_trial.value:.6f}\")\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(CONFIG['output_dir'])\n",
    "\n",
    "print(f\"\\nSaving results to {CONFIG['output_dir']}...\")\n",
    "\n",
    "# Save best parameters\n",
    "best_params_path = output_path / \"best_params.json\"\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump(best_trial.params, f, indent=2)\n",
    "print(f\"✓ Saved best params to {best_params_path}\")\n",
    "\n",
    "# Save study information\n",
    "study_info_path = output_path / \"study_info.json\"\n",
    "with open(study_info_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'best_value': best_trial.value,\n",
    "        'best_trial': best_trial.number,\n",
    "        'n_trials': len(study.trials),\n",
    "        'n_complete_trials': len([t for t in study.trials if t.state.name == 'COMPLETE'])\n",
    "    }, f, indent=2)\n",
    "print(f\"✓ Saved study info to {study_info_path}\")\n",
    "\n",
    "# Save all trials to CSV\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_csv_path = output_path / \"trials.csv\"\n",
    "trials_df.to_csv(trials_csv_path, index=False)\n",
    "print(f\"✓ Saved {len(trials_df)} trials to {trials_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_visualizations(trials_df, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Create Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "summary_path = output_path / \"sweep_summary.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"GCN HYPERPARAMETER SWEEP SUMMARY\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    f.write(f\"Total Trials: {len(study.trials)}\\n\")\n",
    "    f.write(f\"Complete Trials: {len([t for t in study.trials if t.state.name == 'COMPLETE'])}\\n\")\n",
    "    f.write(f\"Pruned Trials: {len([t for t in study.trials if t.state.name == 'PRUNED'])}\\n\\n\")\n",
    "\n",
    "    f.write(\"BEST TRIAL RESULTS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"Trial Number: {best_trial.number}\\n\")\n",
    "    f.write(f\"Best Validation Loss: {best_trial.value:.6f}\\n\\n\")\n",
    "\n",
    "    f.write(\"Best Hyperparameters:\\n\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        f.write(f\"  {key}: {value}\\n\")\n",
    "\n",
    "    f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    f.write(\"HYPERPARAMETER SEARCH SPACE\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    f.write(\"hidden_dim: [16, 256] (step 8)\\n\")\n",
    "    f.write(\"dropout: [0.0, 0.5] (step 0.05)\\n\")\n",
    "    f.write(\"learning_rate: [1e-5, 1e-1] (log scale)\\n\")\n",
    "    f.write(\"weight_decay: [0.0, 1e-2] (log scale)\\n\")\n",
    "    f.write(\"batch_size: {16, 32, 64, 128}\\n\")\n",
    "    f.write(\"mask_prob: [0.1, 0.5] (step 0.05)\\n\")\n",
    "    f.write(\"early_stopping_patience: [5, 30] (step 5)\\n\")\n",
    "\n",
    "print(f\"✓ Saved summary to {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SWEEP COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nAll results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Display Top 5 Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTOP 5 TRIALS:\\n\")\n",
    "top_5 = trials_df.nsmallest(5, 'value')\n",
    "for idx, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "    print(f\"Rank {idx}: Loss = {row['value']:.6f}\")\n",
    "    param_cols = [col for col in row.index if col.startswith('params_')]\n",
    "    for col in param_cols:\n",
    "        param_name = col.replace('params_', '')\n",
    "        print(f\"  {param_name}: {row[col]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Download Results\n",
    "\n",
    "Your results have been saved to Google Drive and are ready to download!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results location:\")\n",
    "print(f\"  Local: {output_path}\")\n",
    "print(f\"  Google Drive: {CONFIG['output_dir']}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "for file in sorted(output_path.iterdir()):\n",
    "    print(f\"  - {file.name}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
