# SAE Feature Ablation Guide

## Overview

The ablation scripts allow you to test the causal impact of individual SAE latent features on downstream GNN performance. This helps identify which learned features are critical vs redundant.

## How It Works

1. **Load original activations**: Layer2 activations (64-dim) from test graphs
2. **Encode to latent space**: Use trained SAE to encode activations → latent features
3. **Ablate specific features**: Zero out selected latent features (e.g., z69, z200)
4. **Reconstruct activations**: Decode back to 64-dim using SAE decoder
5. **Evaluate GNN impact**: Run GNN layer3 with both original and ablated activations, compare outputs

## Scripts

### 1. Single Feature Ablation: `run_ablation.py`

Ablate one or more specific features and measure impact.

**Usage:**
```bash
# Ablate a single feature
python run_ablation.py --latent_dim 512 --k 32 --feature z69

# Ablate multiple features
python run_ablation.py --latent_dim 512 --k 32 --feature z69,z200,z154

# Ablate top N most correlated features (from motif analysis)
python run_ablation.py --latent_dim 512 --k 32 --top_n 10
```

**Outputs:**
- `ablations/activations/{experiment}/graph_{id}.pt` - Reconstructed activations after ablation
- `ablations/results/{experiment}_results.csv` - Detailed metrics per graph
- `ablations/plots/{experiment}_summary.png` - 4-panel visualization

**Metrics Computed:**
- `reconstruction_mse`: MSE between original and ablated activations
- `n_affected_nodes`: How many nodes have changed activations
- `gnn_output_mse`: MSE between GNN outputs with original vs ablated activations
  - **Critical feature**: Large output MSE (predictions change significantly)
  - **Redundant feature**: Near-zero output MSE (predictions unchanged)

### 2. Batch Ablation: `run_batch_ablations.py`

Systematically ablate multiple features and compare impact.

**Usage:**
```bash
# Ablate top 10 most correlated features (default)
python run_batch_ablations.py --latent_dim 512 --k 32

# Ablate top 20 features
python run_batch_ablations.py --latent_dim 512 --k 32 --top_n 20
```

**Outputs:**
- `ablations/results/ablation_comparison.csv` - Comparison table across all ablated features
- `ablations/plots/ablation_comparison.png` - 4-panel comparison visualization
  - Reconstruction error by feature (which features are hardest to ablate)
  - % Nodes affected by feature
  - GNN loss change by feature (which features are most critical)
  - Impact vs breadth scatter plot

## Interpreting Results

### Key Metrics

1. **GNN Output MSE** (most important for causal importance)
   - `MSE > 0.001`: **Critical feature** - ablation significantly changes GNN predictions
   - `0.0001 < MSE < 0.001`: **Moderate feature** - some impact on predictions
   - `MSE < 0.0001`: **Redundant feature** - minimal impact on downstream task

2. **Reconstruction MSE**
   - High MSE: Feature captures significant variance in activations
   - Low MSE: Feature is sparse or redundant with other features

3. **Nodes Affected %**
   - High %: Broadly active feature
   - Low %: Sparse, specialized feature

### Example Interpretation

```csv
feature,reconstruction_mse,nodes_affected_pct,gnn_output_mse
z154,0.0234,78.3,0.0156  # Critical: high impact, broad, important
z298,0.0187,45.2,0.0003  # Interpretable but redundant
z69,0.0012,12.1,0.0001   # Sparse, minimal impact
```

**z154**: High reconstruction error, affects 78% of nodes, **output MSE = 0.0156** when ablated
→ This is a **critical feature** - ablating it significantly changes GNN predictions

**z298**: Moderate reconstruction error, moderate breadth, **output MSE = 0.0003**
→ This feature is **interpretable** (captures some variance) but **redundant** for the GNN task

**z69**: Low reconstruction error, sparse, **output MSE = 0.0001**
→ This is a **dead or minimally useful feature** for the GNN

## Prerequisites

### Required Files

1. **Trained SAE model**: `checkpoints/sae_latent{dim}_k{k}.pt`
2. **Trained GNN model**: `checkpoints/gnn_model.pt`
3. **Layer2 activations**: `outputs/activations/layer2/test/graph_{id}.pt`
4. **Test graph IDs**: `outputs/test_graph_ids.json`
5. **Original graphs**: `virtual_graphs/data/all_graphs/raw_graphs/graph_{id}.pkl`

### Optional (for `--top_n` mode)

6. **Motif correlations**: `outputs/feature_motif_correlations_configurable.csv`
   - Generated by running the motif analysis notebook

## Workflow Example

### 1. Identify Features of Interest

First, run the motif analysis notebook to identify features correlated with specific motifs:

```bash
jupyter notebook sae_activations_motif_new.ipynb
```

This generates `outputs/feature_motif_correlations_configurable.csv` with significance testing results.

### 2. Test Specific Feature

Suppose z154 shows strong correlation with feedforward loops (rpb=0.23, p<0.001). Test if it's critical:

```bash
python run_ablation.py --latent_dim 512 --k 32 --feature z154
```

Check `ablations/results/latent512_k32_ablate_z154_results.csv`:
- If `gnn_output_mse > 0.001`: Feature is critical - ablating it changes GNN predictions
- If `gnn_output_mse ≈ 0`: Feature is interpretable but not causally important for GNN

### 3. Systematic Comparison

Compare top 20 features to find the most critical:

```bash
python run_batch_ablations.py --latent_dim 512 --k 32 --top_n 20
```

Review `ablations/results/ablation_comparison.csv` to rank features by importance.

## Tips

1. **Start small**: Test 1-2 features first to verify the pipeline works
2. **Check GNN model**: Ensure `checkpoints/gnn_model.pt` exists and is trained
3. **Seed consistency**: The same graph will have the same mask across runs (seed=42+graph_id)
4. **Multiple features**: Ablating multiple features together tests their joint importance
5. **Negative controls**: Ablate a known dead feature (low activation) to verify Δ loss ≈ 0

## Troubleshooting

**GNN evaluation shows all `None`:**
- Check that `checkpoints/gnn_model.pt` exists
- Verify graph files exist in `virtual_graphs/data/all_graphs/raw_graphs/`
- Ensure test graph IDs exist in `outputs/test_graph_ids.json`

**No top features found:**
- Run motif analysis notebook first to generate correlation results
- Check that `outputs/feature_motif_correlations_configurable.csv` exists

**High reconstruction error for all features:**
- This could indicate the SAE model isn't well-trained
- Try a different SAE configuration (different latent_dim or k)

**All GNN output MSE values are very small:**
- This is normal! The GNN is robust to small changes in layer2 activations
- Look for relative differences - the highest MSE features are still the most important
- Features with MSE > mean + 2*std are likely critical
